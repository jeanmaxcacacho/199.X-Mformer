{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBvJA88oSJXKDo7PdJ4t2V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeanmaxcacacho/199.X-Mformer/blob/main/Mformer_replicate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TODOs in this notebook:\n",
        "*   get sample data from our actual dataset\n",
        "*   instantiate all Mformer foundations\n",
        "*   obtain moral foundation measurements for all foundations"
      ],
      "metadata": {
        "id": "VcKZuod96SIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "FOUNDATIONS = [\n",
        "    \"authority\",\n",
        "    \"care\",\n",
        "    \"fairness\",\n",
        "    \"loyalty\",\n",
        "    \"sanctity\"\n",
        "]\n",
        "\n",
        "MODEL_FOUNDATIONS = []\n",
        "for F in FOUNDATIONS:\n",
        "  MODEL_FOUNDATIONS.append(f\"joshnguyen/mformer-{F}\")\n",
        "\n",
        "\"\"\"\n",
        "Pretrained models locked and loaded in MODELS as:\n",
        "(tokenizer, model)\n",
        "\n",
        "[0] - [4] respectively\n",
        "1. authority\n",
        "2. care\n",
        "3. fairness\n",
        "4. loyalty\n",
        "5. sanctity\n",
        "\"\"\"\n",
        "\n",
        "MODELS = []\n",
        "for MODEL_FOUNDATION in MODEL_FOUNDATIONS:\n",
        "  MODELS.append((\n",
        "      AutoTokenizer.from_pretrained(MODEL_FOUNDATION),\n",
        "      AutoModelForSequenceClassification.from_pretrained(\n",
        "          MODEL_FOUNDATION,\n",
        "          device_map=\"auto\"\n",
        "      )\n",
        "  ))"
      ],
      "metadata": {
        "id": "csAzjjAce-w0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Load 5 texts from the dataset: https://www.kaggle.com/datasets/asaniczka/reddit-on-israel-palestine-daily-updated\n",
        "...then perform inference\n",
        "\n",
        "Sample texts were obtained arbitrarily from the preview table, these were not properly sampled!\n",
        "\"\"\"\n",
        "\n",
        "instances = [\n",
        "  \"who confiscates a small child's bike? nazis\",\n",
        "  \"Why aren't they deliberately hitting schools and hospitals? Amateurs!\",\n",
        "  \"What are you expecting? That the UN will declare a war on a country to save the sorry hide of hamas?\",\n",
        "  \"Superman says NO to genocide!\",\n",
        "  \"Only criminals hide their faces. Hope they het the pineapple treatment on hell\"\n",
        "]"
      ],
      "metadata": {
        "id": "9BpbiBTOe_VY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AUTHORITY\n",
        "authority_tokenizer = MODELS[0][0]\n",
        "authority_classifier = MODELS[0][1]\n",
        "\n",
        "authority_inputs = authority_tokenizer(\n",
        "    instances,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_tensors='pt'\n",
        ").to(authority_classifier.device)\n",
        "\n",
        "authority_classifier.eval()\n",
        "with torch.no_grad():\n",
        "  authority_outputs = authority_classifier(**authority_inputs)\n",
        "\n",
        "authority_probs = torch.softmax(authority_outputs.logits, dim=1)\n",
        "authority_probs = authority_probs[:, 1]\n",
        "authority_probs = authority_probs.detach().cpu().numpy()\n",
        "\n",
        "print(f\"Probability of foundation 'AUTHORITY':\", \"\\n\")\n",
        "for instance, prob in zip(instances, authority_probs):\n",
        "    print(instance, \"->\", prob, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Spzw45hvkT2w",
        "outputId": "5fb6a2cf-8c59-416f-c61e-3f99df6a0632"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of foundation 'AUTHORITY': \n",
            "\n",
            "who confiscates a small child's bike? nazis -> 0.3475795 \n",
            "\n",
            "Why aren't they deliberately hitting schools and hospitals? Amateurs! -> 0.2956997 \n",
            "\n",
            "What are you expecting? That the UN will declare a war on a country to save the sorry hide of hamas? -> 0.27424964 \n",
            "\n",
            "Superman says NO to genocide! -> 0.22523473 \n",
            "\n",
            "Only criminals hide their faces. Hope they het the pineapple treatment on hell -> 0.22267361 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CARE\n",
        "care_tokenizer = MODELS[1][0]\n",
        "care_classifier = MODELS[1][1]\n",
        "\n",
        "care_inputs = care_tokenizer(\n",
        "    instances,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_tensors='pt'\n",
        ").to(care_classifier.device)\n",
        "\n",
        "care_classifier.eval()\n",
        "with torch.no_grad():\n",
        "  care_outputs = care_classifier(**care_inputs)\n",
        "\n",
        "care_probs = torch.softmax(care_outputs.logits, dim=1)\n",
        "care_probs = care_probs[:, 1]\n",
        "care_probs = care_probs.detach().cpu().numpy()\n",
        "\n",
        "print(f\"Probability of foundation 'CARE':\", \"\\n\")\n",
        "for instance, prob in zip(instances, care_probs):\n",
        "    print(instance, \"->\", prob, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmgm_SuenW8B",
        "outputId": "c940a02d-075c-44a7-84e8-a7e6a837ce35"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of foundation 'CARE': \n",
            "\n",
            "who confiscates a small child's bike? nazis -> 0.3594455 \n",
            "\n",
            "Why aren't they deliberately hitting schools and hospitals? Amateurs! -> 0.19800054 \n",
            "\n",
            "What are you expecting? That the UN will declare a war on a country to save the sorry hide of hamas? -> 0.561702 \n",
            "\n",
            "Superman says NO to genocide! -> 0.8456664 \n",
            "\n",
            "Only criminals hide their faces. Hope they het the pineapple treatment on hell -> 0.31601465 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FAIRNESS\n",
        "fairness_tokenizer = MODELS[2][0]\n",
        "fairness_classifier = MODELS[2][1]\n",
        "\n",
        "fairness_inputs = fairness_tokenizer(\n",
        "    instances,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_tensors='pt'\n",
        ").to(fairness_classifier.device)\n",
        "\n",
        "fairness_classifier.eval()\n",
        "with torch.no_grad():\n",
        "  fairness_outputs = fairness_classifier(**fairness_inputs)\n",
        "\n",
        "fairness_probs = torch.softmax(fairness_outputs.logits, dim=1)\n",
        "fairness_probs = fairness_probs[:, 1]\n",
        "fairness_probs = fairness_probs.detach().cpu().numpy()\n",
        "\n",
        "print(f\"Probability of foundation 'FAIRNESS':\", \"\\n\")\n",
        "for instance, prob in zip(instances, fairness_probs):\n",
        "    print(instance, \"->\", prob, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM-xWfwDp3tM",
        "outputId": "ada1f18c-7329-46ae-d970-20e16ade797e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of foundation 'FAIRNESS': \n",
            "\n",
            "who confiscates a small child's bike? nazis -> 0.67864925 \n",
            "\n",
            "Why aren't they deliberately hitting schools and hospitals? Amateurs! -> 0.24773857 \n",
            "\n",
            "What are you expecting? That the UN will declare a war on a country to save the sorry hide of hamas? -> 0.19757043 \n",
            "\n",
            "Superman says NO to genocide! -> 0.53763705 \n",
            "\n",
            "Only criminals hide their faces. Hope they het the pineapple treatment on hell -> 0.50723505 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOYALTY\n",
        "loyalty_tokenizer = MODELS[3][0]\n",
        "loyalty_classifier = MODELS[3][1]\n",
        "\n",
        "loyalty_inputs = loyalty_tokenizer(\n",
        "    instances,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_tensors='pt'\n",
        ").to(loyalty_classifier.device)\n",
        "\n",
        "loyalty_classifier.eval()\n",
        "with torch.no_grad():\n",
        "  loyalty_outputs = loyalty_classifier(**loyalty_inputs)\n",
        "\n",
        "loyalty_probs = torch.softmax(loyalty_outputs.logits, dim=1)\n",
        "loyalty_probs = loyalty_probs[:, 1]\n",
        "loyalty_probs = loyalty_probs.detach().cpu().numpy()\n",
        "\n",
        "print(f\"Probability of foundation 'LOYALTY':\", \"\\n\")\n",
        "for instance, prob in zip(instances, loyalty_probs):\n",
        "    print(instance, \"->\", prob, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiYp0rEzqKkN",
        "outputId": "f87a9113-ec14-4b6c-9cf9-4f7b4372bd0c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of foundation 'LOYALTY': \n",
            "\n",
            "who confiscates a small child's bike? nazis -> 0.019190745 \n",
            "\n",
            "Why aren't they deliberately hitting schools and hospitals? Amateurs! -> 0.0067726853 \n",
            "\n",
            "What are you expecting? That the UN will declare a war on a country to save the sorry hide of hamas? -> 0.0074807405 \n",
            "\n",
            "Superman says NO to genocide! -> 0.15861931 \n",
            "\n",
            "Only criminals hide their faces. Hope they het the pineapple treatment on hell -> 0.024015982 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SANCTITY\n",
        "sanctity_tokenizer = MODELS[4][0]\n",
        "sanctity_classifier = MODELS[4][1]\n",
        "\n",
        "sanctity_inputs = sanctity_tokenizer(\n",
        "    instances,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_tensors='pt'\n",
        ").to(sanctity_classifier.device)\n",
        "\n",
        "sanctity_classifier.eval()\n",
        "with torch.no_grad():\n",
        "  sanctity_outputs = sanctity_classifier(**sanctity_inputs)\n",
        "\n",
        "sanctity_probs = torch.softmax(sanctity_outputs.logits, dim=1)\n",
        "sanctity_probs = sanctity_probs[:, 1]\n",
        "sanctity_probs = sanctity_probs.detach().cpu().numpy()\n",
        "\n",
        "print(f\"Probability of foundation 'SANCTITY':\", \"\\n\")\n",
        "for instance, prob in zip(instances, sanctity_probs):\n",
        "    print(instance, \"->\", prob, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OM3v7lDhqYOK",
        "outputId": "7bb0acb9-6df6-42bc-9aa3-a198d79d55f4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of foundation 'SANCTITY': \n",
            "\n",
            "who confiscates a small child's bike? nazis -> 0.07356864 \n",
            "\n",
            "Why aren't they deliberately hitting schools and hospitals? Amateurs! -> 0.19583298 \n",
            "\n",
            "What are you expecting? That the UN will declare a war on a country to save the sorry hide of hamas? -> 0.18396676 \n",
            "\n",
            "Superman says NO to genocide! -> 0.30274275 \n",
            "\n",
            "Only criminals hide their faces. Hope they het the pineapple treatment on hell -> 0.31580466 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y2eqZiPAqsfV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}